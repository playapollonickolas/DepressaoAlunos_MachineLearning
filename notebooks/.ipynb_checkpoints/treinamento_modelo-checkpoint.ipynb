{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f74f569",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import (classification_report, confusion_matrix, \n",
        "                             accuracy_score, precision_score, recall_score, \n",
        "                             f1_score, roc_auc_score, roc_curve)\n",
        "\n",
        "# Modelos\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Balanceamento\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"TREINAMENTO DE MODELOS - PREDI√á√ÉO DE DEPRESS√ÉO EM ESTUDANTES\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85a6312e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. CARREGAMENTO E PREPARA√á√ÉO DOS DADOS\n",
        "\n",
        "print(\"\\n[ETAPA 1] CARREGAMENTO DOS DADOS\\n\")\n",
        "\n",
        "df = pd.read_csv('../data/student_depression_dataset.csv')\n",
        "print(f\"‚úì Dataset carregado: {len(df)} registros, {len(df.columns)} colunas\")\n",
        "\n",
        "# C√≥pia para preservar original\n",
        "df_original = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1f87d07",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. PR√â-PROCESSAMENTO\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"[ETAPA 2] PR√â-PROCESSAMENTO DOS DADOS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n‚Üí Tratamento de valores ausentes...\")\n",
        "# Remove linhas com valores ausentes (ou usa fillna se preferir)\n",
        "df = df.dropna()\n",
        "print(f\"  ‚úì Dataset ap√≥s remo√ß√£o de NaN: {len(df)} registros\")\n",
        "\n",
        "# Identifica coluna target\n",
        "depression_col = [col for col in df.columns if 'depress' in col.lower() or 'target' in col.lower()]\n",
        "if depression_col:\n",
        "    target_col = depression_col[0]\n",
        "else:\n",
        "    # Se n√£o encontrar, assume √∫ltima coluna\n",
        "    target_col = df.columns[-1]\n",
        "\n",
        "print(f\"\\n‚Üí Coluna target identificada: '{target_col}'\")\n",
        "\n",
        "# Codifica√ß√£o de vari√°veis categ√≥ricas\n",
        "print(\"\\n‚Üí Codificando vari√°veis categ√≥ricas...\")\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "if target_col in categorical_cols:\n",
        "    categorical_cols.remove(target_col)\n",
        "\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "    print(f\"  ‚úì {col} codificado\")\n",
        "\n",
        "# Codifica target se necess√°rio\n",
        "if df[target_col].dtype == 'object':\n",
        "    le_target = LabelEncoder()\n",
        "    df[target_col] = le_target.fit_transform(df[target_col])\n",
        "    label_encoders['target'] = le_target\n",
        "    print(f\"  ‚úì Target '{target_col}' codificado\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6622047",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. SEPARA√á√ÉO DE FEATURES E TARGET\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"[ETAPA 3] SEPARA√á√ÉO DOS DADOS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Separa features (X) e target (y)\n",
        "X = df.drop(target_col, axis=1)\n",
        "y = df[target_col]\n",
        "\n",
        "print(f\"\\n‚Üí Features (X): {X.shape}\")\n",
        "print(f\"‚Üí Target (y): {y.shape}\")\n",
        "\n",
        "# Verifica balanceamento\n",
        "print(f\"\\n‚Üí Distribui√ß√£o da vari√°vel target:\")\n",
        "print(y.value_counts())\n",
        "print(f\"\\n‚Üí Propor√ß√£o:\")\n",
        "for value, count in y.value_counts(normalize=True).items():\n",
        "    print(f\"  Classe {value}: {count*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "838be819",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. DIVIS√ÉO TREINO/TESTE\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"[ETAPA 4] DIVIS√ÉO TREINO/TESTE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\n‚Üí Treino: {len(X_train)} amostras ({len(X_train)/len(X)*100:.1f}%)\")\n",
        "print(f\"‚Üí Teste: {len(X_test)} amostras ({len(X_test)/len(X)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d02dbb4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. NORMALIZA√á√ÉO DOS DADOS\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"[ETAPA 5] NORMALIZA√á√ÉO (STANDARDIZATION)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"\\n‚úì Dados normalizados (m√©dia=0, desvio padr√£o=1)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e254ea35",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. BALANCEAMENTO COM SMOTE (SE NECESS√ÅRIO)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"[ETAPA 6] BALANCEAMENTO DE CLASSES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Verifica se h√° desbalanceamento significativo\n",
        "class_counts = y_train.value_counts()\n",
        "ratio = class_counts.max() / class_counts.min()\n",
        "\n",
        "print(f\"\\n‚Üí Raz√£o de desbalanceamento: {ratio:.2f}\")\n",
        "\n",
        "if ratio > 2:\n",
        "    print(\"Dataset desbalanceado! Aplicando SMOTE...\")\n",
        "    \n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
        "    \n",
        "    print(f\"\\n‚Üí Antes do SMOTE: {len(X_train_scaled)} amostras\")\n",
        "    print(f\"‚Üí Depois do SMOTE: {len(X_train_balanced)} amostras\")\n",
        "    print(f\"\\n‚Üí Nova distribui√ß√£o:\")\n",
        "    print(pd.Series(y_train_balanced).value_counts())\n",
        "    \n",
        "    # Usa dados balanceados\n",
        "    X_train_final = X_train_balanced\n",
        "    y_train_final = y_train_balanced\n",
        "else:\n",
        "    print(\"‚úì Dataset equilibrado, SMOTE n√£o necess√°rio\")\n",
        "    X_train_final = X_train_scaled\n",
        "    y_train_final = y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e68e41e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. TREINAMENTO DE M√öLTIPLOS MODELOS\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"[ETAPA 7] TREINAMENTO E COMPARA√á√ÉO DE MODELOS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Dicion√°rio de modelos\n",
        "modelos = {\n",
        "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(random_state=42, n_estimators=100),\n",
        "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'SVM': SVC(random_state=42, probability=True),\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=5)\n",
        "}\n",
        "\n",
        "# Armazena resultados\n",
        "resultados = []\n",
        "\n",
        "print(\"\\n‚Üí Treinando e avaliando modelos...\\n\")\n",
        "\n",
        "for nome, modelo in modelos.items():\n",
        "    print(f\"[{nome}]\")\n",
        "    \n",
        "    # Treina\n",
        "    modelo.fit(X_train_final, y_train_final)\n",
        "    \n",
        "    # Predi√ß√µes\n",
        "    y_pred = modelo.predict(X_test_scaled)\n",
        "    y_pred_proba = modelo.predict_proba(X_test_scaled)[:, 1] if hasattr(modelo, 'predict_proba') else None\n",
        "    \n",
        "    # M√©tricas\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    \n",
        "    # Cross-validation\n",
        "    cv_scores = cross_val_score(modelo, X_train_final, y_train_final, cv=5)\n",
        "    cv_mean = cv_scores.mean()\n",
        "    cv_std = cv_scores.std()\n",
        "    \n",
        "    print(f\"  Acur√°cia: {accuracy:.4f}\")\n",
        "    print(f\"  Precis√£o: {precision:.4f}\")\n",
        "    print(f\"  Recall: {recall:.4f}\")\n",
        "    print(f\"  F1-Score: {f1:.4f}\")\n",
        "    print(f\"  CV Score: {cv_mean:.4f} (+/- {cv_std:.4f})\")\n",
        "    \n",
        "    # AUC-ROC (se bin√°rio)\n",
        "    if len(np.unique(y)) == 2 and y_pred_proba is not None:\n",
        "        auc = roc_auc_score(y_test, y_pred_proba)\n",
        "        print(f\"  AUC-ROC: {auc:.4f}\")\n",
        "    else:\n",
        "        auc = None\n",
        "    \n",
        "    print()\n",
        "    \n",
        "    resultados.append({\n",
        "        'Modelo': nome,\n",
        "        'Acur√°cia': accuracy,\n",
        "        'Precis√£o': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1,\n",
        "        'CV Score': cv_mean,\n",
        "        'CV Std': cv_std,\n",
        "        'AUC-ROC': auc\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5204339",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. COMPARA√á√ÉO VISUAL DOS MODELOS\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"[ETAPA 8] COMPARA√á√ÉO VISUAL DOS MODELOS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "df_resultados = pd.DataFrame(resultados)\n",
        "print(\"\\nüìä TABELA DE RESULTADOS:\\n\")\n",
        "print(df_resultados.to_string(index=False))\n",
        "\n",
        "# Gr√°fico comparativo\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Acur√°cia\n",
        "df_resultados.sort_values('Acur√°cia', ascending=True).plot(\n",
        "    x='Modelo', y='Acur√°cia', kind='barh', ax=axes[0, 0], \n",
        "    color='steelblue', legend=False\n",
        ")\n",
        "axes[0, 0].set_title('Acur√°cia por Modelo', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Acur√°cia')\n",
        "axes[0, 0].grid(axis='x', alpha=0.3)\n",
        "\n",
        "# F1-Score\n",
        "df_resultados.sort_values('F1-Score', ascending=True).plot(\n",
        "    x='Modelo', y='F1-Score', kind='barh', ax=axes[0, 1], \n",
        "    color='coral', legend=False\n",
        ")\n",
        "axes[0, 1].set_title('F1-Score por Modelo', fontsize=12, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('F1-Score')\n",
        "axes[0, 1].grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Precis√£o e Recall\n",
        "df_resultados_sorted = df_resultados.sort_values('Acur√°cia')\n",
        "x = np.arange(len(df_resultados_sorted))\n",
        "width = 0.35\n",
        "axes[1, 0].barh(x - width/2, df_resultados_sorted['Precis√£o'], width, label='Precis√£o', color='mediumseagreen')\n",
        "axes[1, 0].barh(x + width/2, df_resultados_sorted['Recall'], width, label='Recall', color='tomato')\n",
        "axes[1, 0].set_yticks(x)\n",
        "axes[1, 0].set_yticklabels(df_resultados_sorted['Modelo'])\n",
        "axes[1, 0].set_xlabel('Score')\n",
        "axes[1, 0].set_title('Precis√£o vs Recall', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Cross-Validation Score\n",
        "df_resultados.sort_values('CV Score', ascending=True).plot(\n",
        "    x='Modelo', y='CV Score', kind='barh', ax=axes[1, 1], \n",
        "    color='mediumpurple', legend=False\n",
        ")\n",
        "axes[1, 1].set_title('Cross-Validation Score', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('CV Score')\n",
        "axes[1, 1].grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../visualizations/comparacao_modelos.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a087e42",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9. SELE√á√ÉO DO MELHOR MODELO\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"[ETAPA 9] SELE√á√ÉO DO MELHOR MODELO\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Seleciona melhor modelo baseado em F1-Score\n",
        "melhor_idx = df_resultados['F1-Score'].idxmax()\n",
        "melhor_modelo_nome = df_resultados.loc[melhor_idx, 'Modelo']\n",
        "melhor_modelo = modelos[melhor_modelo_nome]\n",
        "\n",
        "print(f\"\\nMELHOR MODELO: {melhor_modelo_nome}\")\n",
        "print(f\"F1-Score: {df_resultados.loc[melhor_idx, 'F1-Score']:.4f}\")\n",
        "print(f\"Acur√°cia: {df_resultados.loc[melhor_idx, 'Acur√°cia']:.4f}\")\n",
        "\n",
        "# Retreina o melhor modelo (j√° est√° treinado, mas por clareza)\n",
        "melhor_modelo.fit(X_train_final, y_train_final)\n",
        "y_pred_final = melhor_modelo.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81fdd2fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 10. AN√ÅLISE DETALHADA DO MELHOR MODELO\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"[ETAPA 10] AN√ÅLISE DETALHADA DO MELHOR MODELO\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nRELAT√ìRIO DE CLASSIFICA√á√ÉO:\\n\")\n",
        "print(classification_report(y_test, y_pred_final))\n",
        "\n",
        "# Matriz de Confus√£o\n",
        "print(\"\\MATRIZ DE CONFUS√ÉO:\\n\")\n",
        "cm = confusion_matrix(y_test, y_pred_final)\n",
        "print(cm)\n",
        "\n",
        "# Visualiza√ß√£o da Matriz de Confus√£o\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
        "            xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
        "plt.title(f'Matriz de Confus√£o - {melhor_modelo_nome}', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Verdadeiro')\n",
        "plt.xlabel('Predito')\n",
        "plt.tight_layout()\n",
        "plt.savefig('../visualizations/matriz_confusao.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Curva ROC (se bin√°rio)\n",
        "if len(np.unique(y)) == 2:\n",
        "    y_pred_proba_final = melhor_modelo.predict_proba(X_test_scaled)[:, 1]\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_final)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred_proba_final)\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('Taxa de Falsos Positivos')\n",
        "    plt.ylabel('Taxa de Verdadeiros Positivos')\n",
        "    plt.title(f'Curva ROC - {melhor_modelo_nome}', fontsize=14, fontweight='bold')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../visualizations/curva_roc.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# Feature Importance (se dispon√≠vel)\n",
        "if hasattr(melhor_modelo, 'feature_importances_'):\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"[ETAPA 11] IMPORT√ÇNCIA DAS FEATURES\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': X.columns,\n",
        "        'Import√¢ncia': melhor_modelo.feature_importances_\n",
        "    }).sort_values('Import√¢ncia', ascending=False)\n",
        "    \n",
        "    print(\"\\nTOP 10 FEATURES MAIS IMPORTANTES:\\n\")\n",
        "    print(feature_importance.head(10).to_string(index=False))\n",
        "    \n",
        "    # Visualiza√ß√£o\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    top_features = feature_importance.head(15)\n",
        "    plt.barh(range(len(top_features)), top_features['Import√¢ncia'])\n",
        "    plt.yticks(range(len(top_features)), top_features['Feature'])\n",
        "    plt.xlabel('Import√¢ncia')\n",
        "    plt.title(f'Top 15 Features - {melhor_modelo_nome}', fontsize=14, fontweight='bold')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.grid(axis='x', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../visualizations/feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "514a058e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 12. SALVAMENTO DO MODELO E ARTEFATOS\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"[ETAPA 12] SALVAMENTO DO MODELO\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Salva o melhor modelo\n",
        "with open('../models/modelo_depressao.pkl', 'wb') as f:\n",
        "    pickle.dump(melhor_modelo, f)\n",
        "print(f\"\\n‚úì Modelo salvo: ../models/modelo_depressao.pkl\")\n",
        "\n",
        "# Salva o scaler\n",
        "with open('../models/scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "print(f\"‚úì Scaler salvo: ../models/scaler.pkl\")\n",
        "\n",
        "# Salva os label encoders\n",
        "with open('../models/label_encoders.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encoders, f)\n",
        "print(f\"‚úì Label Encoders salvos: ../models/label_encoders.pkl\")\n",
        "\n",
        "# Salva nomes das features\n",
        "with open('../models/feature_names.pkl', 'wb') as f:\n",
        "    pickle.dump(X.columns.tolist(), f)\n",
        "print(f\"‚úì Feature names salvos: ../models/feature_names.pkl\")\n",
        "\n",
        "# Salva informa√ß√µes do modelo\n",
        "model_info = {\n",
        "    'modelo_nome': melhor_modelo_nome,\n",
        "    'acuracia': df_resultados.loc[melhor_idx, 'Acur√°cia'],\n",
        "    'f1_score': df_resultados.loc[melhor_idx, 'F1-Score'],\n",
        "    'precisao': df_resultados.loc[melhor_idx, 'Precis√£o'],\n",
        "    'recall': df_resultados.loc[melhor_idx, 'Recall'],\n",
        "    'target_col': target_col,\n",
        "    'n_features': len(X.columns),\n",
        "    'n_samples_train': len(X_train),\n",
        "    'n_samples_test': len(X_test)\n",
        "}\n",
        "\n",
        "with open('../models/model_info.pkl', 'wb') as f:\n",
        "    pickle.dump(model_info, f)\n",
        "print(f\"‚úì Informa√ß√µes do modelo salvas: ../models/model_info.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75da10ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 13. RESUMO FINAL\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RESUMO FINAL DO TREINAMENTO\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\"\"\n",
        "TREINAMENTO CONCLU√çDO COM SUCESSO!\n",
        "\n",
        "ESTAT√çSTICAS:\n",
        "Total de modelos testados: {len(modelos)}\n",
        "Melhor modelo: {melhor_modelo_nome}\n",
        "Acur√°cia final: {df_resultados.loc[melhor_idx, 'Acur√°cia']:.4f}\n",
        "F1-Score final: {df_resultados.loc[melhor_idx, 'F1-Score']:.4f}\"\"\")\n",
        "\n",
        "print(\"=\"*70)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
